{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8947708,"sourceType":"datasetVersion","datasetId":5384521}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import des bibliothèques nécessaires**","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom pathlib import Path\nimport warnings\n\n# Ignorer tous les avertissements\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Copier les fichiers du répertoire Input vers le répertoire Working**","metadata":{}},{"cell_type":"code","source":"# Source directory\nsrc_dir_test = \"/kaggle/input/dogs-cats/test/test\"\nsrc_dir_train = \"/kaggle/input/dogs-cats/train/train\"\n\n# Destination directory\ndst_dir_test = \"/kaggle/working/test\"\ndst_dir_train = \"/kaggle/working/train\"\n\n# Remove the destination directory if it exists\nif os.path.exists(dst_dir_test):\n    shutil.rmtree(dst_dir_test)\n\nif os.path.exists(dst_dir_train):\n    shutil.rmtree(dst_dir_train)\n\n# Copy the entire directory and its contents recursively\nshutil.copytree(src_dir_test, dst_dir_test)\nshutil.copytree(src_dir_train, dst_dir_train)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Afficher quelques exemples d'images de chats et de chiens**","metadata":{}},{"cell_type":"code","source":"# Chemin des données\ntrain_dir = '/kaggle/working/train'\n\nfig, ax = plt.subplots(2, 5, figsize=(15, 6))\ncategories = ['cats', 'dogs']\nfor i, category in enumerate(categories):\n    category_path = os.path.join(train_dir, category)\n    images = os.listdir(category_path)[:5]\n    for j, img_name in enumerate(images):\n        img_path = os.path.join(category_path, img_name)\n        img = load_img(img_path, target_size=(150, 150))\n        ax[i, j].imshow(img)\n        ax[i, j].axis('off')\n        ax[i, j].set_title(f\"{category} {j}\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"markdown","source":"**Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"def create_generators(train_dir, img_size=(150, 150), batch_size=32):\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.1)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='training')\n\n    validation_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='validation')\n\n    return train_generator, validation_generator\n\n# Chemins des dossiers de données\ntrain_dir = '/kaggle/working/train'\n\n# Création des générateurs de données\ntrain_generator, validation_generator = create_generators(train_dir)\n\n# Affichage de quelques informations sur les générateurs\nprint(f\"Nombre d'images dans le jeu d'entraînement : {train_generator.samples}\")\nprint(f\"Nombre d'images dans le jeu de validation : {validation_generator.samples}\")\n\n# Exemple d'utilisation des générateurs pour récupérer un lot d'images\nbatch_images, batch_labels = next(train_generator)\nprint(f\"Shape du batch d'images : {batch_images.shape}\")\nprint(f\"Shape du batch de labels : {batch_labels.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n# Définir la taille des lots pour l'entraînement\nbatch_size = 64 #32\n\n# Utiliser MirroredStrategy pour le parallélisme multi-CPU\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n    # Créer le modèle CNN\n    def create_model(input_shape=(150, 150, 3)):\n        model = Sequential([\n            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n            MaxPooling2D(pool_size=(2, 2)),\n\n            Conv2D(64, (3, 3), activation='relu'),\n            MaxPooling2D(pool_size=(2, 2)),\n\n            Conv2D(128, (3, 3), activation='relu'),\n            MaxPooling2D(pool_size=(2, 2)),\n\n            Flatten(),\n            Dense(512, activation='relu'),\n            Dropout(0.5),\n            Dense(1, activation='sigmoid')\n        ])\n\n        model.compile(loss='binary_crossentropy',\n                      optimizer='adam',\n                      metrics=['accuracy'])\n        return model\n\n    # Créer et compiler le modèle\n    model = create_model()\n\n    # Entraîner le modèle\n    history = model.fit(\n        train_generator,\n        steps_per_epoch=train_generator.samples // batch_size,\n        epochs=50,\n        validation_data=validation_generator,\n        validation_steps=validation_generator.samples // batch_size\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sauvegarder le modèle**","metadata":{}},{"cell_type":"code","source":"# Directory to save the model\nsave_dir = '/kaggle/working/saved_models'\n\n# Remove the directory if it exists\nif os.path.exists(save_dir):\n    shutil.rmtree(save_dir)\n\n# Create the directory\nos.makedirs(save_dir)\n\n# Assuming model is already created and trained\n# Save the model\nmodel.save(os.path.join(save_dir, 'model.h5'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prédictions**","metadata":{}},{"cell_type":"code","source":"# Load the saved model\nmodel = load_model('/kaggle/working/saved_models/model.h5')\n\n# Function to preprocess the image\ndef preprocess_image(img_path, img_size=(150, 150)):\n    img = image.load_img(img_path, target_size=img_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0\n    return img_array\n\n# Function to make predictions\ndef make_prediction(img_path):\n    img_array = preprocess_image(img_path)\n    prediction = model.predict(img_array)\n    return 'Dog' if prediction[0][0] > 0.5 else 'Cat'\n\n# Get list of test images\ntest_dir = Path('/kaggle/working/test')\ntest = list(test_dir.glob('*.jpg'))\n\n# Create a tf.data.Dataset from the image paths\ndef load_and_preprocess_image(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [150, 150])\n    img = img / 255.0\n    return img, path\n\ntest_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in test])\ntest_ds = test_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntest_ds = test_ds.batch(32)\ntest_ds = test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n\n# Make predictions in parallel\npredictions = []\nfile_paths = []\nfor batch, paths in test_ds:\n    batch_preds = model.predict(batch)\n    batch_preds = ['Dog' if pred > 0.5 else 'Cat' for pred in batch_preds]\n    predictions.extend(batch_preds)\n    file_paths.extend(paths.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Display the results**","metadata":{}},{"cell_type":"code","source":"# Display some images with their predictions\ndef display_images_with_predictions(df, num_images=50):\n    import tensorflow.keras.preprocessing.image as image  # Import inside the function to ensure scope\n    plt.figure(figsize=(20, 40))  # Adjust figure size as needed\n    for i in range(num_images):\n        img_path = df.iloc[i]['FilePath']\n        prediction = df.iloc[i]['Prediction']\n        img = image.load_img(img_path, target_size=(150, 150))\n        plt.subplot(10, 5, i + 1)  # Adjust layout to 10 rows and 5 columns\n        plt.imshow(img)\n        plt.title(prediction)\n        plt.axis('off')\n    plt.show()\n\n# Display the first 50 images with predictions\ndisplay_images_with_predictions(results_df, num_images=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}